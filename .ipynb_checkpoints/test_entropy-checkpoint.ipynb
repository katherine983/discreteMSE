{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484c835d",
   "metadata": {},
   "source": [
    "# Demo of Discrete ApEn and SampEn Algorithms  \n",
    "The following notebook demonstrates the implementations of Approximate Entropy and Sample Entropy in the discreteMSE package. These implementations are specific for use on discrete valued time series where the filter parameter, r, is suppressed and only exact vector matches are counted. The demonstration is divided into three sections:  \n",
    "1. Section 1 provides a review of Approximate Entropy  \n",
    "The theory and exact implementation of this is explained below.\n",
    "\n",
    "*Note: In this demonstration, all discussion of indexing or elements at index i assumes a series or sequence indexed at 1 for the first element, as opposed to the Python indexing convention which starts at i=0. This means that some of the indexing used in the Python code blocks will not align completely with that used in the text. Therefore when the range $1 \\leq i \\leq N-m$ is given in the text below, this is equivalent to the range $0 \\leq i \\leq N-m-1$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdafa534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa2a02",
   "metadata": {},
   "source": [
    "## Theory of Approximate Entropy  \n",
    "Approximate Entropy (ApEn) was proposed by Pincus [1] to address the issue of estimating the conditional entropy of finite “real-world” sample sequences. It takes two parameters, *m* and *r*, and works as follows:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e2ad77",
   "metadata": {},
   "source": [
    "Given a time series sequence *X* of *N* data points, and parameter values $m=2$ and $r=1$;\n",
    "1. Using a sliding window of size *m*, generate a set of vectors of *m* sequential data points from *X*.  \n",
    "\n",
    "    - Ex. If *X* = \\[1, 1, 1, 3, 1, 2, 2, 3, 1, 2\\], $N=10$ and $m=2$,  then the set of *m*-vectors should be  \n",
    "    \\[\\[1, 1\\], \\[1, 1\\], \\[1, 3\\], \\[3, 1\\], \\[1, 2\\], \\[2, 2\\], \\[2, 3\\], \\[3, 1\\], \\[1, 2\\]\\].\n",
    "    \n",
    "        - Note there are $N-m+1=10-2+1=9$ vectors in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "192775f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xmi:  [[1 1]\n",
      " [1 1]\n",
      " [1 3]\n",
      " [3 1]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [2 3]\n",
      " [3 1]\n",
      " [1 2]]\n",
      "z = 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([1, 1, 1, 3, 1, 2, 2, 3, 1, 2])\n",
    "m = 2\n",
    "r = 1\n",
    "N = len(X)\n",
    "#xmi is the set of m-vectors \n",
    "xmi = np.array([X[i:i+m] for i in range(len(X)-m+1)])\n",
    "#z is the number of m-vectors in xmi\n",
    "z = len(xmi)\n",
    "print(\"xmi: \", xmi)\n",
    "print(\"z =\", z)\n",
    "#z should equal (N-m+1)\n",
    "z == N-m+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51180e4e",
   "metadata": {},
   "source": [
    "2. For each vector, $x_m(i)$, in the set, calculate the maximum elementwise distance (Chebyshev distance) as $d[x_m(i), x_m(j)] = max(|X_{i+k} - X_{j+k}|), for 0\\leq k\\leq m-1$, from each of the vectors, $x_m(j), 1 \\leq j \\leq N-m+1$, in the set.  \n",
    "  \n",
    "    - Ex. Continuing the example above, for $i=1$, $x_m(1)$ = \\[1, 1\\], the max distance, $d[x_m(1), x_m(3)]$, between $x_m(1)$ and $x_m(3)$ is calculated as $max(|[(1-1), (1-3)]|) = max([0, 2]) = 2$. The max distance between $x_m(1)$ and each $x_m(j), 1\\leq j\\leq N-m+1$ is and listed here:  \n",
    "    \\[0, 0, 2, 2, 1, 1, 2, 2, 1\\]  \n",
    "    *Note that the ApEn algorithm includes the distance between $x_m(i)$ and itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8aa4e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 2 2 1 1 2 2 1]\n",
      " [0 0 2 2 1 1 2 2 1]\n",
      " [2 2 0 2 1 1 1 2 1]\n",
      " [2 2 2 0 2 1 2 0 2]\n",
      " [1 1 1 2 0 1 1 2 0]\n",
      " [1 1 1 1 1 0 1 1 1]\n",
      " [2 2 1 2 1 1 0 2 1]\n",
      " [2 2 2 0 2 1 2 0 2]\n",
      " [1 1 1 2 0 1 1 2 0]]\n"
     ]
    }
   ],
   "source": [
    "#create 3d array of xmi vectors where each xi in xmi is its own 1xm subarray\n",
    "xi_matrix = np.stack([xmi], axis=2).reshape((z,1,m))\n",
    "#Calculate the Chebyshev distance between each xmi and xmj\n",
    "#first get the absolute elementwise difference between each xmi, xmj vector\n",
    "dif = np.abs(xi_matrix - xmi)\n",
    "#print(dif)\n",
    "#then calculate the max difference for each xmi,xmj pair\n",
    "maxdist = dif.max(axis=2)\n",
    "print(maxdist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9204af4c",
   "metadata": {},
   "source": [
    "3. Let $B_i$ equal the number of vectors, $x_m(j)$, whose Chebyshev distance from $x_m(i)$ is less than or equal to the parameter *r*. (*r* is called the filter or tolerance parameter because it defines the tolerance within which two vectors may be considered matching.)  \n",
    "  \n",
    "    - Ex. For the above, for $r=1$, and at $i=0$, $B_0 = 5$ and the list of each $B_i$ is \n",
    "    \\[5, 5, 5, 3, 7, 9, 5, 3, 7\\]  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "040d87dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 3, 7, 9, 5, 3, 7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bi = np.sum(maxdist<=r, axis=1)\n",
    "Bi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e8c258",
   "metadata": {},
   "source": [
    "4. For each $i$, $1 \\leq i \\leq N-m+1$, calculate the value $C_i^m(r) = B_i/(N-m+1)$.\n",
    "    - Ex. For $i=0$, $C_0^m(r=1) = 5/9 = 0.5556$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96693646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55555556 0.55555556 0.55555556 0.33333333 0.77777778 1.\n",
      " 0.55555556 0.33333333 0.77777778]\n"
     ]
    }
   ],
   "source": [
    "Cmi = Bi/(N-m+1)\n",
    "print(Cmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e17b6f",
   "metadata": {},
   "source": [
    "5. Then compute the value $\\phi^m(r) = (N-m+1)^{-1} \\sum_{i=1}^{N-m+1} ln C_i^m(r)$ \n",
    "    - Ex. $\\phi^m(r) = (9)^{-1} * [ln(5/9)+ln(5/9)+ln(5/9)+ln(3/9)+ln(7/9)+ln(9/9)+ln(5/9)+ln(3/9)+ln(7/9)] = -0.561$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8911973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.561222232611834\n"
     ]
    }
   ],
   "source": [
    "phim = (1/(N-m+1)) * np.log(Cmi).sum()\n",
    "print(phim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f966748",
   "metadata": {},
   "source": [
    "6. Repeat steps 1 and 2, except instead of the set of *m*-length vectors, use the set of *N-m* number of vectors of *m+1* sequential data points (i.e. created using a sliding window of size *m+1*).  \n",
    "\n",
    "    - Ex. For the above, *X* = \\[1, 1, 1, 3, 1, 2, 2, 3, 1, 2\\], the set of *N-m* *m+1*-length vectors in *X* should be  \n",
    "    \\[[1, 1, 1], [1, 1, 3], [1, 3, 1], [3, 1, 2], [1, 2, 2], [2, 2, 3], [2, 3, 1], [3, 1, 2]\\]  \n",
    "    - For $x_{m+1}(0)$ = \\[1, 1, 1\\], the Chebyshev distance from each $x_{m+1}(j)$,  $1 \\leq j \\leq N-m$ is:  \n",
    "    \\[0, 2, 2, 2, 1, 2, 2, 2\\]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00d91cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xki:  [[1 1 1]\n",
      " [1 1 3]\n",
      " [1 3 1]\n",
      " [3 1 2]\n",
      " [1 2 2]\n",
      " [2 2 3]\n",
      " [2 3 1]\n",
      " [3 1 2]]\n",
      "z = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let k equal m+1\n",
    "k = m+1\n",
    "#xm1i is the set of m+1-vectors \n",
    "xm1i = np.array([X[i:i+k] for i in range(len(X)-k+1)])\n",
    "#z is the number of m+1-vectors in xm1i\n",
    "z = len(xm1i)\n",
    "print(\"xm1i: \", xm1i)\n",
    "print(\"z =\", z)\n",
    "#z should equal (N-m)\n",
    "z == N-m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69c90948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 2 2 1 2 2 2]\n",
      " [2 0 2 2 1 1 2 2]\n",
      " [2 2 0 2 1 2 1 2]\n",
      " [2 2 2 0 2 1 2 0]\n",
      " [1 1 1 2 0 1 1 2]\n",
      " [2 1 2 1 1 0 2 1]\n",
      " [2 2 1 2 1 2 0 2]\n",
      " [2 2 2 0 2 1 2 0]]\n"
     ]
    }
   ],
   "source": [
    "#create 3d array of xm1i vectors where each xi in xm1i is its own 1xm+1 subarray\n",
    "xm1i_matrix = np.stack([xm1i], axis=2).reshape((z,1,k))\n",
    "difm1 = np.abs(xm1i_matrix - xm1i)\n",
    "#get max distance between each x_m+1(i) and x_m+1(j) pair\n",
    "maxdistm1 = difm1.max(axis=2)\n",
    "print(maxdistm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81527db3",
   "metadata": {},
   "source": [
    "7. For each $x_{m+1}(i)$, range $1 \\leq i \\leq N-m$, in the set of *m+1*-length vectors, let $A_i$ equal the number of *m+1* vectors, $x_{m+1}(j)$, $1 \\leq j \\leq N-m$, whose Chebyshev distance from $x_{m+1}(i)$ is less than or equal to *r* and let $C_i^{m+1}(r)$ equal $A_i/(N-m)$.\n",
    "\n",
    "    - Ex. For i=0, $A_0 = 2$ and $C_0^{m+1}(r) = 2/8$\n",
    "    - The list of each $A_i$ would be \n",
    "    \\[2, 3, 3, 3, 6, 5, 3, 3\\]\n",
    "    \n",
    "8. Then $\\phi^{m+1}(r) = (N-m)^{-1} \\sum_{i=1}^{N-m} ln C_i^{m+1}(r)$.\n",
    "    - Ex. $\\phi^{m+1}(r) = (8)^{-1} * [ln(2/8)+ln(3/8)+ln(3/8)+ln(3/8)+ln(6/8)+ln(5/8)+ln(3/8)+ln(3/8)] = -0.881$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81de5bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of Ai:  [2 3 3 3 6 5 3 3]\n",
      "Array of C_i^m+1:  [0.25  0.375 0.375 0.375 0.75  0.625 0.375 0.375]\n",
      "Phi^m+1:  -0.8810157909845048\n"
     ]
    }
   ],
   "source": [
    "Ai = np.sum(maxdistm1<=r, axis=1)\n",
    "print(\"Array of Ai: \", Ai)\n",
    "Cm1i = Ai/(N-m)\n",
    "print(\"Array of C_i^m+1: \", Cm1i)\n",
    "phim1 = (1/(N-m)) * np.log(Cm1i).sum()\n",
    "print(\"Phi^m+1: \", phim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce90d43",
   "metadata": {},
   "source": [
    "      \n",
    "      \n",
    "9. Finally, **ApEn(m, r)** is defined as $\\lim_{N\\to\\infty} [\\phi^m(r) - \\phi^{m+1}(r)]$ which is estimated by the statistic:  \n",
    "$$\n",
    "\\begin{split}\n",
    "ApEn(m, r, N) &= \\phi^m(r) - \\phi^{m+1}(r) \\\\\n",
    "&= (N-m+1)^{-1}\\sum_{i=1}^{N-m+1} ln(B_i/(N-m+1)) - (N-m)^{-1} \\sum_{i=1}^{N-m} ln(A_i/(N-m))\n",
    "\\end{split}\n",
    "$$  \n",
    "    - Ex. In the running example, $ApEn(m,r,N)=-0.561 - (-0.881) = 0.320$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "480260ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31979355837267076"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ApEn = phim - phim1\n",
    "ApEn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52883b2",
   "metadata": {},
   "source": [
    "However, the above statistic is typically approximated by only considering the range $1 \\leq i \\leq N-m$ for the calculation of $B_i$ as well as $A_i$, thus excluding the *m*-length vector at index $i=N-m+1$, and allowing the formula to be simplified as follows:\n",
    "$$\n",
    "ApEn(m,r,N) \\approx (N-m)^{-1} \\sum_{i=1}^{N-m}-ln(A_i/B_i)\n",
    "$$\n",
    "- For the above example, ApEn(m,r,N) would equal 0.253."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c552a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 3 6 8 4 3]\n"
     ]
    }
   ],
   "source": [
    "#ApEn approximation\n",
    "#get array of Bi, the counts of m-length vector matches\n",
    "#xmi is the set of m-vectors\n",
    "xmi = np.array([X[i:i+m] for i in range(len(X[:-1])-m+1)])\n",
    "#z is the number of m-vectors in xmi\n",
    "z = len(xmi)\n",
    "xi_matrix = np.stack([xmi], axis=2).reshape((z,1,m))\n",
    "#Calculate the Chebyshev distance between each xmi and xmj\n",
    "#first get the absolute elementwise difference between each xmi, xmj vector\n",
    "dif = np.abs(xi_matrix - xmi)\n",
    "#print(dif)\n",
    "#then calculate the max difference for each xmi,xmj pair\n",
    "maxdist = dif.max(axis=2)\n",
    "Bi = np.sum(maxdist<=r, axis=1)\n",
    "print(Bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b5b4062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 3 3 6 5 3 3]\n"
     ]
    }
   ],
   "source": [
    "#get array of Ai, the counts of m+1-length vector matches\n",
    "#let k equal m+1\n",
    "k = m+1\n",
    "#xm1i is the set of m+1-vectors \n",
    "xm1i = np.array([X[i:i+k] for i in range(len(X)-k+1)])\n",
    "#z is the number of m+1-vectors in xm1i\n",
    "z = len(xm1i)\n",
    "#create 3d array of xm1i vectors where each xi in xm1i is its own 1xm+1 subarray\n",
    "xm1i_matrix = np.stack([xm1i], axis=2).reshape((z,1,k))\n",
    "difm1 = np.abs(xm1i_matrix - xm1i)\n",
    "#get max distance between each x_m+1(i) and x_m+1(j) pair\n",
    "maxdistm1 = difm1.max(axis=2)\n",
    "Ai = np.sum(maxdistm1<=r, axis=1)\n",
    "print(Ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1618cb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25327462839512793"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate ApEn approximation\n",
    "ApEn = np.sum(np.negative(np.log(Ai/Bi)))/(N-m)\n",
    "ApEn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97507346",
   "metadata": {},
   "source": [
    "Nearly all applications of ApEn in the literature use this approximation, including those from Pincus in the papers developing the measure for use on physiologic time series [4]. For large values of *N*, the difference between the original ApEn formulation and the algorithmic simplified version is <0.05 when $N-m+1\\geq90$ and <0.02 when $N-m+1\\geq283$ [2]. From here on in this demonstration, unless otherwise explicitly stated, references to the ApEn algorithm will imply the approximate formulation: $ApEn(m,r,N) = (N-m)^{-1} \\sum_{i=1}^{N-m}-ln(A_i/B_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47141ea5",
   "metadata": {},
   "source": [
    "ApEn is not intended to be an estimate of the true entropy rate or K-S entropy of a sequence but rather Pincus asserts it should be regarded as a family of statistics measuring the degree of sequence regularity[1], [3]. While the Shannon entropy rate and K-S entropy are designed to estimate the average rate of information gain as $N\\rightarrow\\infty$, ApEn was designed to be used to study the evolution of a system’s complexity over time [3] and compare the irregularity of finite, short sequences (*N*=1000). For ApEn to be valid, Pincus and Goldberger recommend data with at least $N=10m$  data points. However, ApEn is biased for shorter sequences because it includes self-counting when tabulating vector matches. This produces an overestimation of the regularity in the sequence because vectors which only match themselves for m+1 points, will contribute a value of ln(1/1)=0 to the sum, thus skewing the ApEn value towards 0 implying regularity, even though, intuitively, having a large number of vectors which only match themselves should equate to higher irregularity [2]. Sample Entropy (SampEn) aims to rectify this bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4fc1b3",
   "metadata": {},
   "source": [
    "## Theory of Sample Entropy\n",
    "Richman and Moorman [2] introduced SampEn as an alternative to the ApEn formula that reduces the amount of bias in the sequence regularity estimate. First, similarly to the ApEn algorithmic simplification, SampEn excludes the *m*-length vector at index *N-m+1*, thus ensuring there are corresponding $x_m(i)$ and $x_{m+1}(i)$ for all $i, 1 \\leq i \\leq N-m$. Second, SampEn does not include self-matches in the tabulation of $B_i$ and $A_i$. Finally, while ApEn takes the negative sum of the logarithm of each $A_i/B_i$ ratio for $1 \\leq i \\leq N-m$, SampEn takes the logarithm of the ratio of the total number of *m+1*-length vector matches to the total number of *m*-length vector matches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacf8f3",
   "metadata": {},
   "source": [
    "A step by step of the SampEn algorithm presented in [2] is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592557f6",
   "metadata": {},
   "source": [
    "Given a time series sequence $X$ of $N$ data points, and parameter values $m=2$ and $r=1$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d836636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 1, 1, 3, 1, 2, 2, 3, 1, 2])\n",
    "m=2\n",
    "r=1\n",
    "N=len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7120457",
   "metadata": {},
   "source": [
    "1. In the same way as in ApEn, obtain the set of *m*-length vectors in $X$ in the range $1\\leq i \\leq N-m$.\n",
    "2. Calculate the Chebyshev distance between each $x_m(i)$ and each $x_m(j)$ for $1\\leq i \\leq N-m$, $1\\leq j \\leq N-m, (j\\neq i)$, where the Chebyshev distance $d[x_m(i),x_m(j)]$ is the max absolute difference between the elements of the two vectors from $X$, given by $max(|X_{i+k} - X_{j+k}|), 0\\leq k\\leq m-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9d96647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get array of Bmi, the counts of m-length vector matches\n",
    "#xmi is the set of m-vectors\n",
    "xmi = np.array([X[i:i+m] for i in range(len(X[:-1])-m+1)])\n",
    "#z is the number of m-vectors in xmi\n",
    "z = len(xmi)\n",
    "xi_matrix = np.stack([xmi], axis=2).reshape((z,1,m))\n",
    "#Calculate the Chebyshev distance between each xmi and xmj\n",
    "#first get the absolute elementwise difference between each xmi, xmj vector\n",
    "dif = np.abs(xi_matrix - xmi)\n",
    "#print(dif)\n",
    "#then calculate the max difference for each xmi,xmj pair\n",
    "maxdist = dif.max(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d118fb",
   "metadata": {},
   "source": [
    "3. Define the value $B_i^m(r)$ as $(N-m-1)^{-1}$ times the number of vectors $x_m(j)$ where $d[x_m(i),x_m(j)] \\leq r$ for all *j* in range $1 \\leq j \\leq N-m, (j\\neq i)$. \n",
    "One interpretation of $B_i^m(r)$, when *r* is small enough, is $B_i^m(r)$ is the proportional frequency of the vector $x_m(i)$ in $X$ excluding itself, thus the term $(N-m-1)^{-1}$ is used for the normalization and not $(N-m)^{-1}$ since only $N-m-1$ are considered when counting matches of $x_m(i)$. If we interpret the value $B_i$ from the ApEn calculation in the previous section as the frequency of vectors matching $x_m(i)$ in $X$, then $B_i^m(r) = (N-m-1)^{-1}(B_i - 1)$.  \n",
    "\n",
    "    - Ex. With the same sequence from the ApEn demonstration, *X* = \\[1, 1, 1, 3, 1, 2, 2, 3, 1, 2\\], $N=10$ and $m=2$, and set of *m*-vectors \\[\\[1, 1\\], \\[1, 1\\], \\[1, 3\\], \\[3, 1\\], \\[1, 2\\], \\[2, 2\\], \\[2, 3\\], \\[3, 1\\], \\[1, 2\\]\\].  \n",
    "    - Recall the max distance between $x_m(1)$ and each $x_m(j)$, $1\\leq j \\leq N-m$ was \\[0, 0, 2, 2, 1, 1, 2, 2\\]\n",
    "    - Therefore, the number of $x_m(j)$ matching $x_m(1)$, given by $B_1$, is 4 and the indices of the matching $x_m(j)$ are 1, 2, 5, and 6. If we exclude $x_m(j)$ where $j = i$, then we remove the vector at index 1 and the new total number of $x_m(j)$ matches is 3, which is equivalent to the expression $B_1 - 1$. \n",
    "    - Following this we can calculate $B_1^m$ as $(B_1 - 1)/(N-m-1) = 3/7 = 0.429$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "415a2f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 3 6 8 4 3]\n",
      "[0.42857143 0.42857143 0.42857143 0.28571429 0.71428571 1.\n",
      " 0.42857143 0.28571429]\n"
     ]
    }
   ],
   "source": [
    "Bi = np.sum(maxdist<=r, axis=1)\n",
    "print(Bi)\n",
    "Bmi = (Bi - 1)/(N-m-1)\n",
    "print(Bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe29ce",
   "metadata": {},
   "source": [
    "4. Repeat steps 1 and 2, except instead of the set of *m*-length vectors, use the *N-m* set of vectors of *m+1* sequential data points (i.e. created using a sliding window of size *m+1*). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let k equal m+1\n",
    "k = m+1\n",
    "#xm1i is the set of m+1-vectors \n",
    "xm1i = np.array([X[i:i+k] for i in range(len(X)-k+1)])\n",
    "#z is the number of m+1-vectors in xm1i\n",
    "z = len(xm1i)\n",
    "#create 3d array of xm1i vectors where each xi in xm1i is its own 1xm+1 subarray\n",
    "xm1i_matrix = np.stack([xm1i], axis=2).reshape((z,1,k))\n",
    "difm1 = np.abs(xm1i_matrix - xm1i)\n",
    "#get max distance between each x_m+1(i) and x_m+1(j) pair\n",
    "maxdistm1 = difm1.max(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b182f54",
   "metadata": {},
   "source": [
    "5. Next define the value $A_i^m(r)$ as $(N-m-1)^{-1}$ times the number of vectors $x_{m+1}(j)$ where $d[x_{m+1}(i),x_{m+1}(j)] \\leq r$ for all *j* in range $1 \\leq j \\leq N-m, (j\\neq i)$. As we did with the value $B_i^m(r)$, we can use the formula $A_i^m(r) = (A_i - 1)/(N-m-1)$.\n",
    "    - Ex. The max distance between $x_{m+1}(1)$ and each $x_{m+1}(j)$ is \\[0, 2, 2, 2, 1, 2, 2, 2\\].\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14acfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ai = np.sum(maxdistm1<=r, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46950314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fb28833",
   "metadata": {},
   "source": [
    "One interpretation of $B_i^m(r)$, when *r* is small enough, is $B_i^m(r)$ is the proportional frequency of the vector $x_m(i)$ in $X$ excluding itself, thus the term $(N-m-1)^{-1}$ is used for the normalization and not $(N-m)^{-1}$ since only $N-m-1$ are considered when counting matches of $x_m(i)$. If we interpret the value $B_i$ from the ApEn calculation in the previous section as the frequency of vectors matching $x_m(i)$ in $X$, then $B_i^m(r) = (N-m-1)^{-1}(B_i - 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87fff551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.array([6, 1, 6, 8, 7, 2, 2, 7, 5, 2, 5, 5, 4, 5, 5, 6, 6, 1, 1, 1])\n",
    "#X = np.array([1, 1, 1, 3, 1, 2, 2, 3, 1, 2])\n",
    "X = np.array([1, 1, 1, 3, 1, 2, 2, 3, 1, 2])\n",
    "m=2\n",
    "r=0.2\n",
    "N=len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "054968b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example markov chain used by Pincus [1].\n",
    "#alphabet = {1, 2, 3}\n",
    "#transition matrix\n",
    "P = np.array([[0, 0, 2], [3, 0, 0], [0, 3, 1]])/3\n",
    "#get steady state vector vie eigen decomposition of P\n",
    "eigvalues, eigvectors = np.linalg.eig(P)\n",
    "#get index of the eigenvalue equal to 1\n",
    "eig_index = np.where(eigvalues.real.round(1) >= 1.0)\n",
    "#get the column vector at the index corresponding to eigenvalue of 1\n",
    "pibasis = eigvectors[:, eig_index]\n",
    "#normalize it to get the steady state probability vector of P \n",
    "pi = pibasis/pibasis.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51cd5641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.66666667]\n",
      " [1.         0.         0.        ]\n",
      " [0.         1.         0.33333333]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.28571429+0.j]],\n",
       "\n",
       "       [[0.28571429+0.j]],\n",
       "\n",
       "       [[0.42857143+0.j]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(P)\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "623de424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from discreteMSE.entropy import apen, sampen, vector_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "304edefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 3]\n",
      " [3 1]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [2 3]\n",
      " [3 1]\n",
      " [1 2]]\n",
      "---------\n",
      "[[[0 0]\n",
      "  [0 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 0]\n",
      "  [0 1]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 0]\n",
      "  [0 1]]\n",
      "\n",
      " [[0 1]\n",
      "  [0 1]\n",
      "  [0 0]\n",
      "  [1 1]\n",
      "  [0 1]\n",
      "  [1 1]\n",
      "  [1 0]\n",
      "  [1 1]\n",
      "  [0 1]]\n",
      "\n",
      " [[1 0]\n",
      "  [1 0]\n",
      "  [1 1]\n",
      "  [0 0]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [0 0]\n",
      "  [1 1]]\n",
      "\n",
      " [[0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [1 1]\n",
      "  [0 0]\n",
      "  [1 0]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [0 0]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 0]\n",
      "  [0 0]\n",
      "  [0 1]\n",
      "  [1 1]\n",
      "  [1 0]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 0]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [0 1]\n",
      "  [0 0]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 0]\n",
      "  [1 0]\n",
      "  [1 1]\n",
      "  [0 0]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [0 0]\n",
      "  [1 1]]\n",
      "\n",
      " [[0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [1 1]\n",
      "  [0 0]\n",
      "  [1 0]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [0 0]]]\n",
      "[[0 0 1 1 1 2 2 1 1]\n",
      " [0 0 1 1 1 2 2 1 1]\n",
      " [1 1 0 2 1 2 1 2 1]\n",
      " [1 1 2 0 2 2 2 0 2]\n",
      " [1 1 1 2 0 1 2 2 0]\n",
      " [2 2 2 2 1 0 1 2 1]\n",
      " [2 2 1 2 2 1 0 2 2]\n",
      " [1 1 2 0 2 2 2 0 2]\n",
      " [1 1 1 2 0 1 2 2 0]]\n"
     ]
    }
   ],
   "source": [
    "xmi = np.array([data[i:i+m] for i in range(len(data)-m+1)])\n",
    "z = len(xmi)\n",
    "print(xmi)\n",
    "print('---------')\n",
    "#create 3d array of xmi vectors where each xi in xmi is its own 1xm subarray\n",
    "xi_matrix = np.stack([xmi], axis=2).reshape((z,1,m))\n",
    "\n",
    "#dif is a 3D array containing the pairwise kronecker delta between xi and xmi for all xi.\n",
    "dif = np.invert(xi_matrix==xmi).astype(int)\n",
    "print(dif)\n",
    "#dif.sum(axis=2) evaluates to 0 for xi that fully matched and >0 for xi that did not fully match\n",
    "sim_dist = dif.sum(axis=2)\n",
    "print(sim_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ad1a78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sim_dist[:-1,:]==0) - z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "921f6046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-m 8\n",
      "Bi 8 Ai 8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "N = len(data)\n",
    "Bi = vector_matches(data[:-1], m, enttype='apen')\n",
    "k=m+1\n",
    "Ai = vector_matches(data, k, enttype='apen')\n",
    "print('N-m', N-m)\n",
    "print('Bi', len(Bi), 'Ai', len(Ai))\n",
    "print(Bi.shape == Ai.shape)\n",
    "apen = np.sum(np.negative(np.log(Ai/Bi)))/(N-m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45f7d08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc210613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "456d3f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 1. , 1. , 1. , 1. , 1. , 1. ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ai/Bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddcd9db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.69314718, -0.69314718,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(Ai/Bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "115faab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3862943611198906"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.negative(np.log(Ai/Bi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4f43b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17328679513998632"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.negative(np.log(Ai/Bi)))/(N-m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd2f5bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17328679513998632"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ab8f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = vector_matches(data[:-1], m, enttype='sampen')\n",
    "#print(B)\n",
    "\n",
    "#get number of matches, store in variable 'A'\n",
    "k = m+1\n",
    "A = vector_matches(data, k, enttype='sampen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81786d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f0cb1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f67724",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ddf96",
   "metadata": {},
   "source": [
    "[1] <div class=\"csl-entry\">Pincus, S. M. (1991). Approximate entropy as a measure of system complexity. <i>Proceedings of the National Academy of Sciences of the United States of America</i>, <i>88</i>(6), 2297–2301. https://doi.org/10.1073/pnas.88.6.2297</div>\n",
    "[2] <div class=\"csl-entry\">Richman, J. S., &#38; Moorman, J. R. (2000). Physiological time-series analysis using approximate entropy and sample entropy. <i>Americal Journal of Physiology Heart and Circulatory Physiology</i>, <i>278</i>, H2039–H2049.</div>\n",
    "[3] <div class=\"csl-entry\">Pincus, S. M., &#38; Goldberger, A. L. (1994). Physiological time-series analysis: What does regularity quantify? <i>American Journal of Physiology - Heart and Circulatory Physiology</i>, <i>266</i>(4 35-4). https://doi.org/10.1152/ajpheart.1994.266.4.h1643</div>\n",
    "[4] <div class=\"csl-entry\">Delgado-Bonal, A., &#38; Marshak, A. (2019). Approximate entropy and sample entropy: A comprehensive tutorial. In <i>Entropy</i> (Vol. 21, Issue 6). https://doi.org/10.3390/e21060541</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
